{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"12bdcf390b604cc38322fb126d851966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fd28b315c3b4a408f867e89276bd85e","IPY_MODEL_4689bdf1a12c44b59c7eda40593e854f","IPY_MODEL_93953357e9a54d00b13225e41fc572fa"],"layout":"IPY_MODEL_cbfe6cac2c1347a6be552be0b288769b"}},"2fd28b315c3b4a408f867e89276bd85e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb7c320b7ddc4f6ab2d5e6aa191cb6ce","placeholder":"​","style":"IPY_MODEL_2031fea5f43243d6aca0f73ab451ea43","value":"Downloading: 100%"}},"4689bdf1a12c44b59c7eda40593e854f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44dae95043ee48cc88581a6643da15b2","max":1215509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8698ed7d1de9477c96d2aea11aa6b34c","value":1215509}},"93953357e9a54d00b13225e41fc572fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f6c0550f09b4a98a1b8b739847e2860","placeholder":"​","style":"IPY_MODEL_d3af71eb71a547f3803daa258a9f7df5","value":" 1.22M/1.22M [00:01&lt;00:00, 996kB/s]"}},"cbfe6cac2c1347a6be552be0b288769b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb7c320b7ddc4f6ab2d5e6aa191cb6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2031fea5f43243d6aca0f73ab451ea43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44dae95043ee48cc88581a6643da15b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8698ed7d1de9477c96d2aea11aa6b34c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f6c0550f09b4a98a1b8b739847e2860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3af71eb71a547f3803daa258a9f7df5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"695bfe67ec5b4a978320d871c5d4e105":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cb746a478694037be454cfbd2764231","IPY_MODEL_6ab43e12b86841ef9f68f68c63ffbfba","IPY_MODEL_86a65e5fcf5f4329af63ff351a3e1d46"],"layout":"IPY_MODEL_e51024dad0e145b1bec6a2eb30083dec"}},"4cb746a478694037be454cfbd2764231":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6843efc3e374708904e03482b4c278e","placeholder":"​","style":"IPY_MODEL_a53999b2748f42c89cfcc0286be01a59","value":"Downloading: 100%"}},"6ab43e12b86841ef9f68f68c63ffbfba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8076a8f15ef40bdb14c886fb5f9c804","max":434,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2fe4d892dd48648f51cb1cb4d3500e","value":434}},"86a65e5fcf5f4329af63ff351a3e1d46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_811bdba102874647b586a024547ad59a","placeholder":"​","style":"IPY_MODEL_3a737faee52b406b8fb5b83a7a731672","value":" 434/434 [00:00&lt;00:00, 27.9kB/s]"}},"e51024dad0e145b1bec6a2eb30083dec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6843efc3e374708904e03482b4c278e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a53999b2748f42c89cfcc0286be01a59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8076a8f15ef40bdb14c886fb5f9c804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2fe4d892dd48648f51cb1cb4d3500e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"811bdba102874647b586a024547ad59a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a737faee52b406b8fb5b83a7a731672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers 4.9.0\n!pip install datasets transformers[sentencepiece]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvmPbYFLsCMx","outputId":"93447923-822c-4f2a-9759-6cecede1b107","execution":{"iopub.status.busy":"2023-02-10T10:04:35.848175Z","iopub.execute_input":"2023-02-10T10:04:35.849565Z","iopub.status.idle":"2023-02-10T10:04:48.278818Z","shell.execute_reply.started":"2023-02-10T10:04:35.849419Z","shell.execute_reply":"2023-02-10T10:04:48.277898Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n\u001b[31mERROR: Could not find a version that satisfies the requirement 4.9.0 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for 4.9.0\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (8.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.10.1)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.13.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.12.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.7.1)\nRequirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.19.4)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.1.97)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import print_function  \nimport psutil\nprint(psutil.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:04:48.280985Z","iopub.execute_input":"2023-02-10T10:04:48.281318Z","iopub.status.idle":"2023-02-10T10:04:48.287066Z","shell.execute_reply.started":"2023-02-10T10:04:48.281271Z","shell.execute_reply":"2023-02-10T10:04:48.285958Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"5.9.1\n","output_type":"stream"}]},{"cell_type":"code","source":"CUDA_LAUNCH_BLOCKING=1","metadata":{"id":"O9x-4NQmDQ8w","execution":{"iopub.status.busy":"2023-02-10T10:04:48.288656Z","iopub.execute_input":"2023-02-10T10:04:48.288972Z","iopub.status.idle":"2023-02-10T10:04:48.296418Z","shell.execute_reply.started":"2023-02-10T10:04:48.288945Z","shell.execute_reply":"2023-02-10T10:04:48.295263Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"id":"R57NEhea10AL"}},{"cell_type":"code","source":"import torch, random\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\nfrom transformers import BertForSequenceClassification\n\nf1_micro_graphical = 0\nf1_macro_graphical = 0\nacc_graphical = 0\n\nf1_micro_textual = 0\nf1_macro_textual = 0\nacc_textual = 0\n\nf1_micro_ensemble = 0\nf1_macro_ensemble = 0\nacc_ensemble = 0\nfirst_df = pd.read_json('../input/last-3600/last_3660.json',encoding='utf-8')\n# first_df = pd.read_csv('../input/inf-4500/inf_4500.txt', sep=\"\\t\",encoding='utf-16')\n# first_df.drop(first_df.index[[0]], inplace=True)\n# first_df.drop(first_df.columns[[10,11,12,13,14]], axis=1, inplace=True)\n\nfirst_df.drop(first_df.index[[0]], inplace=True)\nprint(len(first_df))\nfirst_df.head(3)\nrandom.seed(0)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"id":"MUZeyuhGstRf","outputId":"71de3c87-6503-4ed3-b0d6-609a81e9224e","execution":{"iopub.status.busy":"2023-02-10T10:07:37.996486Z","iopub.execute_input":"2023-02-10T10:07:37.996922Z","iopub.status.idle":"2023-02-10T10:07:38.106477Z","shell.execute_reply.started":"2023-02-10T10:07:37.996891Z","shell.execute_reply":"2023-02-10T10:07:38.105498Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"3662\n","output_type":"stream"}]},{"cell_type":"code","source":"columns = ['content', 'background','textcolor','font', 'label']\ndf = pd.DataFrame(first_df, columns=columns)\ndf.columns = ['content', 'background','textcolor','font', 'label']\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"8XrZR0p8s0wo","outputId":"76837b91-23d3-48e1-bcc6-9d3b8b442983","execution":{"iopub.status.busy":"2023-02-10T10:07:40.916962Z","iopub.execute_input":"2023-02-10T10:07:40.917467Z","iopub.status.idle":"2023-02-10T10:07:40.938226Z","shell.execute_reply.started":"2023-02-10T10:07:40.917425Z","shell.execute_reply":"2023-02-10T10:07:40.937340Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                content          background  \\\n1     عباس \\nامیر انتظام  شیرمردی در وادی ایران نوین...           pattern_f   \n2         صدا و سیما. شبکه خبر  صدا و سیما؛ شبکه العالم             default   \n3     که تو دنیای منی سبز بمانی همه عمر\\n\\n         ...             default   \n4     تخفیف ویژه کلاسهای خصوصی ارایشگری  ظرفیت فقط 4...  base_background_gd   \n5     چقدر قشنگه یه نفر تو زندگیت باشه که هم عشقت با...             default   \n...                                                 ...                 ...   \n3658  شنیده‌ها درباره حمله به کاروان حزب الله\\n\\nخبر...             default   \n3659  یه سری پس زمینه اینجوری هم داره واسه چس ناله ه...           pattern_g   \n3660  دوستان صبر ایوب خواستن، بعد از ایام عذا پخش می...           pattern_o   \n3661  احتمالا زمان fit کردن مدل یادگیری آرگومان verb...   yellow_background   \n3662  این یک استوری آزمایشی است.\\nکه توسط اپلیکیشن د...   yellow_background   \n\n     textcolor       font                  label  \n1         blue   iransans              monasebat  \n2        white     iphone                 siyasi  \n3        white       suls              monasebat  \n4          red  dastnevis  tablighat va business  \n5        black  dastnevis               asheqane  \n...        ...        ...                    ...  \n3658   default      sahel                 siyasi  \n3659   default      pooya                 majazi  \n3660     white    shabnam              monasebat  \n3661     black      sahel                     IT  \n3662     black   nastaliq                     IT  \n\n[3662 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>background</th>\n      <th>textcolor</th>\n      <th>font</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>عباس \\nامیر انتظام  شیرمردی در وادی ایران نوین...</td>\n      <td>pattern_f</td>\n      <td>blue</td>\n      <td>iransans</td>\n      <td>monasebat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>صدا و سیما. شبکه خبر  صدا و سیما؛ شبکه العالم</td>\n      <td>default</td>\n      <td>white</td>\n      <td>iphone</td>\n      <td>siyasi</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>که تو دنیای منی سبز بمانی همه عمر\\n\\n         ...</td>\n      <td>default</td>\n      <td>white</td>\n      <td>suls</td>\n      <td>monasebat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تخفیف ویژه کلاسهای خصوصی ارایشگری  ظرفیت فقط 4...</td>\n      <td>base_background_gd</td>\n      <td>red</td>\n      <td>dastnevis</td>\n      <td>tablighat va business</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>چقدر قشنگه یه نفر تو زندگیت باشه که هم عشقت با...</td>\n      <td>default</td>\n      <td>black</td>\n      <td>dastnevis</td>\n      <td>asheqane</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>شنیده‌ها درباره حمله به کاروان حزب الله\\n\\nخبر...</td>\n      <td>default</td>\n      <td>default</td>\n      <td>sahel</td>\n      <td>siyasi</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>یه سری پس زمینه اینجوری هم داره واسه چس ناله ه...</td>\n      <td>pattern_g</td>\n      <td>default</td>\n      <td>pooya</td>\n      <td>majazi</td>\n    </tr>\n    <tr>\n      <th>3660</th>\n      <td>دوستان صبر ایوب خواستن، بعد از ایام عذا پخش می...</td>\n      <td>pattern_o</td>\n      <td>white</td>\n      <td>shabnam</td>\n      <td>monasebat</td>\n    </tr>\n    <tr>\n      <th>3661</th>\n      <td>احتمالا زمان fit کردن مدل یادگیری آرگومان verb...</td>\n      <td>yellow_background</td>\n      <td>black</td>\n      <td>sahel</td>\n      <td>IT</td>\n    </tr>\n    <tr>\n      <th>3662</th>\n      <td>این یک استوری آزمایشی است.\\nکه توسط اپلیکیشن د...</td>\n      <td>yellow_background</td>\n      <td>black</td>\n      <td>nastaliq</td>\n      <td>IT</td>\n    </tr>\n  </tbody>\n</table>\n<p>3662 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-26T15:06:21.431702Z","iopub.execute_input":"2023-01-26T15:06:21.432846Z","iopub.status.idle":"2023-01-26T15:06:21.449957Z","shell.execute_reply.started":"2023-01-26T15:06:21.432801Z","shell.execute_reply":"2023-01-26T15:06:21.448038Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"monasebat                359\ntablighat va business    321\nsiyasi                   311\nnasihat va sokhan        253\npezeshki                 213\nasheqane                 204\nelmi                     175\nmazhabi                  174\nmajazi                   172\nzibayi                   167\nejtemayi                 162\nIT                       154\nsher va adabiyat         131\nvarzeshi                 124\nmelk o maskan            123\nangizeshi                118\ntourist va amaken         91\ndars va daneshgah         81\nashpazi                   71\neqtesadi                  65\ntanz                      65\ngreet                     63\nhonar                     31\nagahi                     27\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df = df.groupby('label').filter(lambda x : len(x)>80)\nprint(len(df['label'].value_counts()))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uQfep9wh3nY","outputId":"35830e0a-a303-44cc-a246-46aa68cc72eb","execution":{"iopub.status.busy":"2023-01-23T10:46:06.886947Z","iopub.execute_input":"2023-01-23T10:46:06.887838Z","iopub.status.idle":"2023-01-23T10:46:06.909398Z","shell.execute_reply.started":"2023-01-23T10:46:06.887799Z","shell.execute_reply":"2023-01-23T10:46:06.907845Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"18\n","output_type":"stream"}]},{"cell_type":"code","source":"# remove_list = ['angizeshi',  'sher va adabiyat', 'majazi', 'nasihat va sokhan', 'dars va daneshgah', 'honar eqtesadi','tanz','agahi','greet', 'asheqane', 'honar', 'mazhabi', 'eqtesadi']\n# remove_list = ['dars va daneshgah',  'agahi', 'tanz']\n# for i in remove_list:\n#     df = df[df.label != i]","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:46:06.911148Z","iopub.execute_input":"2023-01-23T10:46:06.912136Z","iopub.status.idle":"2023-01-23T10:46:06.917088Z","shell.execute_reply.started":"2023-01-23T10:46:06.912086Z","shell.execute_reply":"2023-01-23T10:46:06.916151Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class_num = len(df['label'].value_counts())\nclass_num","metadata":{"execution":{"iopub.status.busy":"2023-01-23T10:46:13.568094Z","iopub.execute_input":"2023-01-23T10:46:13.568502Z","iopub.status.idle":"2023-01-23T10:46:13.577032Z","shell.execute_reply.started":"2023-01-23T10:46:13.568468Z","shell.execute_reply":"2023-01-23T10:46:13.575487Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"18"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = [18, 8]\n# df['label'].value_counts(sort=False).plot.bar()\n\n\ndf['label'].value_counts(sort=False).plot(kind=\"bar\")\nplt.xticks( horizontalalignment=\"center\")\nplt.xlabel(\"Label\")\nplt.ylabel(\"Frequency\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-23T11:06:22.387101Z","iopub.execute_input":"2023-01-23T11:06:22.387486Z","iopub.status.idle":"2023-01-23T11:06:23.190291Z","shell.execute_reply.started":"2023-01-23T11:06:22.387441Z","shell.execute_reply":"2023-01-23T11:06:23.189103Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"Text(0, 0.5, 'Frequency')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1296x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"def convert_to_numeric(col):\n  possible_labels = df[col].unique()\n  col_dict = {}\n  for index, possible_label in enumerate(possible_labels):\n      col_dict[possible_label] = index\n  return col_dict\n\ndf['background'] = df.background.replace(convert_to_numeric('background'))\ndf['textcolor'] = df.textcolor.replace(convert_to_numeric('textcolor'))\ndf['font'] = df.font.replace(convert_to_numeric('font'))\n\npossible_labels = df.label.unique()\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\n    \ndf['label'] = df.label.replace(label_dict)\ndf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ZajzYbuptXYG","outputId":"934c068e-8d0c-4341-b323-7a26238f139d","execution":{"iopub.status.busy":"2023-01-20T13:04:03.803187Z","iopub.execute_input":"2023-01-20T13:04:03.804022Z","iopub.status.idle":"2023-01-20T13:04:03.851147Z","shell.execute_reply.started":"2023-01-20T13:04:03.803987Z","shell.execute_reply":"2023-01-20T13:04:03.850168Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                content  background  \\\n1     عباس \\nامیر انتظام  شیرمردی در وادی ایران نوین...           0   \n2         صدا و سیما. شبکه خبر  صدا و سیما؛ شبکه العالم           1   \n3     که تو دنیای منی سبز بمانی همه عمر\\n\\n         ...           1   \n4     تخفیف ویژه کلاسهای خصوصی ارایشگری  ظرفیت فقط 4...           2   \n5     چقدر قشنگه یه نفر تو زندگیت باشه که هم عشقت با...           1   \n...                                                 ...         ...   \n3658  شنیده‌ها درباره حمله به کاروان حزب الله\\n\\nخبر...           1   \n3659  یه سری پس زمینه اینجوری هم داره واسه چس ناله ه...          32   \n3660  دوستان صبر ایوب خواستن، بعد از ایام عذا پخش می...          28   \n3661  احتمالا زمان fit کردن مدل یادگیری آرگومان verb...          11   \n3662  این یک استوری آزمایشی است.\\nکه توسط اپلیکیشن د...          11   \n\n      textcolor  font  label  \n1             0     0      0  \n2             1     1      1  \n3             1     2      0  \n4             2     3      2  \n5             3     3      3  \n...         ...   ...    ...  \n3658          4     9      1  \n3659          4     6      6  \n3660          1    13      0  \n3661          3     9      9  \n3662          3     5      9  \n\n[3333 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>background</th>\n      <th>textcolor</th>\n      <th>font</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>عباس \\nامیر انتظام  شیرمردی در وادی ایران نوین...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>صدا و سیما. شبکه خبر  صدا و سیما؛ شبکه العالم</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>که تو دنیای منی سبز بمانی همه عمر\\n\\n         ...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تخفیف ویژه کلاسهای خصوصی ارایشگری  ظرفیت فقط 4...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>چقدر قشنگه یه نفر تو زندگیت باشه که هم عشقت با...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>شنیده‌ها درباره حمله به کاروان حزب الله\\n\\nخبر...</td>\n      <td>1</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3659</th>\n      <td>یه سری پس زمینه اینجوری هم داره واسه چس ناله ه...</td>\n      <td>32</td>\n      <td>4</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3660</th>\n      <td>دوستان صبر ایوب خواستن، بعد از ایام عذا پخش می...</td>\n      <td>28</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3661</th>\n      <td>احتمالا زمان fit کردن مدل یادگیری آرگومان verb...</td>\n      <td>11</td>\n      <td>3</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3662</th>\n      <td>این یک استوری آزمایشی است.\\nکه توسط اپلیکیشن د...</td>\n      <td>11</td>\n      <td>3</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>3333 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Graphical Classification","metadata":{"id":"si2kW2Dnztc7"}},{"cell_type":"code","source":"np.random.seed(112)\ndf_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n                                     [int(.80*len(df)), int(.90*len(df))])\n\nprint(len(df_train),len(df_val), len(df_test))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fQnmX5ZZGVW","outputId":"50bcbd94-72d6-4c92-a343-3784d5dbc80f","execution":{"iopub.status.busy":"2023-01-20T13:04:03.852414Z","iopub.execute_input":"2023-01-20T13:04:03.852869Z","iopub.status.idle":"2023-01-20T13:04:03.862913Z","shell.execute_reply.started":"2023-01-20T13:04:03.852833Z","shell.execute_reply":"2023-01-20T13:04:03.861689Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"2666 333 334\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import BertTokenizer\nimport torch.nn.functional as Fun\n\nclass GraphicalDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n        self.labels =[label for label in df['label']]\n        self.back = [g for g in df['background']]\n        self.textcolor = [g for g in df['textcolor']]\n        self.font = [g for g in df['font']]\n        \n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        return np.array(self.labels[idx])\n    \n    def get_batch_back(self, idx):\n        return self.back[idx]\n \n    def get_batch_textcolor(self, idx):\n        return self.textcolor[idx]\n\n    def get_batch_font(self, idx):\n        return self.font[idx]\n    \n    def __getitem__(self, idx):\n\n        batch_back  = self.get_batch_back(idx)\n        batch_textcolor  = self.get_batch_textcolor(idx)\n        batch_font  = self.get_batch_font(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        max_value_back = np.max(np.max(df['background'].unique()))\n        values_tensor = torch.tensor(batch_back)\n        output_back = Fun.one_hot(values_tensor, num_classes = max_value_back+1)\n        \n        max_value_textcolor = np.max(np.max(df['textcolor'].unique()))\n        values_tensor = torch.tensor(batch_textcolor)\n        output_textcolor = Fun.one_hot(values_tensor, num_classes = max_value_textcolor+1)\n        \n        max_value_font = np.max(np.max(df['font'].unique()))\n        values_tensor = torch.tensor(batch_font)\n        output_font = Fun.one_hot(values_tensor, num_classes = max_value_font+1)\n        \n        values_tensor1 = torch.tensor((batch_y))\n#         batch_y = Fun.one_hot(values_tensor1, num_classes = 25)\n        return output_back, output_textcolor, output_font, batch_y\n","metadata":{"id":"6JEfu3XmtvhA","execution":{"iopub.status.busy":"2023-01-20T13:04:03.864942Z","iopub.execute_input":"2023-01-20T13:04:03.865553Z","iopub.status.idle":"2023-01-20T13:04:03.877534Z","shell.execute_reply.started":"2023-01-20T13:04:03.865491Z","shell.execute_reply":"2023-01-20T13:04:03.876416Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nfrom transformers import BertModel,AutoModelForMaskedLM,AutoModel\n\nclass GraphicalClassifier(nn.Module):\n\n    def __init__(self):\n\n        super(GraphicalClassifier, self).__init__()\n        \n        seed = 0\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)\n      \n        self.fc_back = nn.Linear(36,100)\n        self.fc_textcolor = nn.Linear(12,100)\n        self.fc_font = nn.Linear(16,100)\n        \n        \n        self.fc_hidden_back = nn.Linear(100,25)\n        self.fc_hidden_textcolor = nn.Linear(100,20)\n        self.fc_hiddent_font = nn.Linear(100,22)\n        \n        self.fc_tab = nn.Linear(25+20+22, class_num)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_back, input_textcolor, input_font):\n\n        mlp_back = self.relu(self.fc_hidden_back(self.relu(self.fc_back(input_back.float()))))\n        mlp_textcolor = self.relu(self.fc_hidden_textcolor(self.relu(self.fc_textcolor(input_textcolor.float()))))\n        mlp_font = self.relu(self.fc_hiddent_font(self.relu(self.fc_font(input_font.float()))))\n        concat_tab = torch.cat(\n             (mlp_back.float(),\n              mlp_textcolor.float(),\n              mlp_font.float()),1)\n        \n        mlp = self.fc_tab(concat_tab)\n        return mlp","metadata":{"id":"lPL6OZJBuQhv","execution":{"iopub.status.busy":"2023-01-20T13:04:03.879468Z","iopub.execute_input":"2023-01-20T13:04:03.879984Z","iopub.status.idle":"2023-01-20T13:04:03.904482Z","shell.execute_reply.started":"2023-01-20T13:04:03.879948Z","shell.execute_reply":"2023-01-20T13:04:03.903732Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_validation_loss = 0.5\n\n    def early_stop(self, validation_loss):\n        if validation_loss < self.min_validation_loss:\n            self.min_validation_loss = validation_loss\n            self.counter = 0\n        elif validation_loss > (self.min_validation_loss + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:04:03.906059Z","iopub.execute_input":"2023-01-20T13:04:03.906736Z","iopub.status.idle":"2023-01-20T13:04:03.914251Z","shell.execute_reply.started":"2023-01-20T13:04:03.906699Z","shell.execute_reply":"2023-01-20T13:04:03.913049Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score ,precision_score, recall_score\n\ndef train(model, train_data, val_data, learning_rate, epochs, batch_size):\n    \n    train, val = GraphicalDataset(train_data), GraphicalDataset(val_data)\n\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size)\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr= learning_rate)\n    \n    early_stopper = EarlyStopper(patience=4, min_delta=0.001)\n\n    if use_cuda:\n            model = model.cuda()\n            criterion = criterion.cuda()\n\n    for epoch_num in range(epochs):\n            total_acc_train = 0\n            total_loss_train = 0\n            \n            for  input_back, input_textcolor, input_font, train_label in tqdm(train_dataloader):\n\n                train_label = train_label.to(device)\n                back = input_back.to(device)\n                textcolor = input_textcolor.to(device)\n                font = input_font.to(device)\n                train_label = train_label.to(device)\n\n                output = model(back, textcolor, font)\n                batch_loss = criterion(output, train_label)\n                total_loss_train += batch_loss.item()\n                \n                acc = (output.argmax(dim=1) == train_label).sum().item()\n                total_acc_train += acc\n\n                model.zero_grad()\n                batch_loss.backward()\n                optimizer.step()\n                    \n            total_acc_val = 0\n            total_loss_val = 0\n            \n            with torch.no_grad():\n            \n                for val_back, val_textcolor, val_font, val_label in val_dataloader:\n\n                    back = val_back.to(device)\n                    textcolor = val_textcolor.to(device)\n                    font = val_font.to(device)\n\n                    output = model(back, textcolor, font)\n                    val_label = val_label.to(device)\n                    batch_loss = criterion(output, val_label)\n                    total_loss_val += batch_loss.item()\n                    \n                    acc = (output.argmax(dim=1) == val_label).sum().item()\n                    total_acc_val += acc\n                    \n                   \n            if early_stopper.early_stop(total_loss_val / len(val_data)): \n                print(\"Early Stopped.\")\n                break\n                \n            print(\n                 f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n                 | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n                 | Val Loss: {total_loss_val / len(val_data): .3f} \\\n                 | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n\n           \n    \nEPOCHS= 200\nmodel = GraphicalClassifier()\nLR = 4e-4\n\nbatch_size = 8\n              \ntrain(model, df_train, df_val, LR, EPOCHS, batch_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeW93ha9v_vJ","outputId":"2de58f0a-a0a8-4e9c-a082-256d2392ac0c","execution":{"iopub.status.busy":"2023-01-20T13:04:03.917122Z","iopub.execute_input":"2023-01-20T13:04:03.917964Z","iopub.status.idle":"2023-01-20T13:05:11.061945Z","shell.execute_reply.started":"2023-01-20T13:04:03.917923Z","shell.execute_reply":"2023-01-20T13:05:11.060899Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 117.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  0.353                  | Train Accuracy:  0.102                  | Val Loss:  0.346                  | Val Accuracy:  0.150\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 177.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Train Loss:  0.336                  | Train Accuracy:  0.183                  | Val Loss:  0.329                  | Val Accuracy:  0.225\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 183.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Train Loss:  0.320                  | Train Accuracy:  0.219                  | Val Loss:  0.317                  | Val Accuracy:  0.228\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 149.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Train Loss:  0.310                  | Train Accuracy:  0.232                  | Val Loss:  0.311                  | Val Accuracy:  0.228\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 179.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 5 | Train Loss:  0.305                  | Train Accuracy:  0.240                  | Val Loss:  0.308                  | Val Accuracy:  0.228\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 180.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 6 | Train Loss:  0.301                  | Train Accuracy:  0.253                  | Val Loss:  0.306                  | Val Accuracy:  0.222\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 184.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 7 | Train Loss:  0.298                  | Train Accuracy:  0.265                  | Val Loss:  0.304                  | Val Accuracy:  0.237\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 181.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 8 | Train Loss:  0.296                  | Train Accuracy:  0.273                  | Val Loss:  0.303                  | Val Accuracy:  0.243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 163.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 9 | Train Loss:  0.294                  | Train Accuracy:  0.276                  | Val Loss:  0.303                  | Val Accuracy:  0.249\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 181.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 10 | Train Loss:  0.292                  | Train Accuracy:  0.280                  | Val Loss:  0.303                  | Val Accuracy:  0.243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 156.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 11 | Train Loss:  0.290                  | Train Accuracy:  0.284                  | Val Loss:  0.303                  | Val Accuracy:  0.243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 162.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 12 | Train Loss:  0.289                  | Train Accuracy:  0.290                  | Val Loss:  0.302                  | Val Accuracy:  0.243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 182.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 13 | Train Loss:  0.288                  | Train Accuracy:  0.293                  | Val Loss:  0.302                  | Val Accuracy:  0.249\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 170.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 14 | Train Loss:  0.287                  | Train Accuracy:  0.297                  | Val Loss:  0.302                  | Val Accuracy:  0.258\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 173.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 15 | Train Loss:  0.286                  | Train Accuracy:  0.299                  | Val Loss:  0.302                  | Val Accuracy:  0.261\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 181.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 16 | Train Loss:  0.285                  | Train Accuracy:  0.300                  | Val Loss:  0.303                  | Val Accuracy:  0.264\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 178.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 17 | Train Loss:  0.284                  | Train Accuracy:  0.302                  | Val Loss:  0.303                  | Val Accuracy:  0.267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 179.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 18 | Train Loss:  0.284                  | Train Accuracy:  0.303                  | Val Loss:  0.303                  | Val Accuracy:  0.267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 175.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 19 | Train Loss:  0.283                  | Train Accuracy:  0.305                  | Val Loss:  0.303                  | Val Accuracy:  0.267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 157.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 20 | Train Loss:  0.282                  | Train Accuracy:  0.303                  | Val Loss:  0.303                  | Val Accuracy:  0.273\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 177.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 21 | Train Loss:  0.282                  | Train Accuracy:  0.304                  | Val Loss:  0.303                  | Val Accuracy:  0.273\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 175.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 22 | Train Loss:  0.281                  | Train Accuracy:  0.305                  | Val Loss:  0.303                  | Val Accuracy:  0.270\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 183.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 23 | Train Loss:  0.281                  | Train Accuracy:  0.305                  | Val Loss:  0.303                  | Val Accuracy:  0.270\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 177.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 24 | Train Loss:  0.280                  | Train Accuracy:  0.304                  | Val Loss:  0.303                  | Val Accuracy:  0.267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 156.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 25 | Train Loss:  0.280                  | Train Accuracy:  0.306                  | Val Loss:  0.303                  | Val Accuracy:  0.267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 166.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 26 | Train Loss:  0.280                  | Train Accuracy:  0.305                  | Val Loss:  0.303                  | Val Accuracy:  0.264\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 162.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 27 | Train Loss:  0.279                  | Train Accuracy:  0.306                  | Val Loss:  0.303                  | Val Accuracy:  0.264\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 181.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 28 | Train Loss:  0.279                  | Train Accuracy:  0.309                  | Val Loss:  0.304                  | Val Accuracy:  0.264\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:01<00:00, 182.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 29 | Train Loss:  0.278                  | Train Accuracy:  0.309                  | Val Loss:  0.304                  | Val Accuracy:  0.267\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [00:02<00:00, 155.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Early Stopped.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ndef evaluate(model, test_data):\n\n    test = GraphicalDataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=8)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    total_acc_test = 0\n    outputs = []\n    labels = []\n    with torch.no_grad():\n         \n        for test_back, test_textcolor, test_font, test_label in test_dataloader:\n        \n            test_label = test_label.to(device)\n            back = test_back.to(device)\n            textcolor = test_textcolor.to(device)\n            font = test_font.to(device)\n\n            output =  model(back, textcolor, font)\n\n            acc = (output.argmax(dim=1) == test_label).sum().item()\n            total_acc_test += acc\n            \n            for i in output.argmax(dim=1).tolist():\n                outputs.append(i)\n            for i in test_label.cpu():\n                labels.append(i)\n    global f1_micro_graphical \n    global f1_macro_graphical \n    global acc_graphical \n    acc_graphical = total_acc_test / len(test_data)\n    f1_macro_graphical = f1_score(outputs, labels, average='macro')\n    f1_micro_graphical = f1_score(outputs, labels, average='micro')\n                       \n    print(f'Test Accuracy: {acc_graphical}')\n    print('F1-Score macro: ',f1_macro_graphical)\n    print('F1-Score micro: ',f1_micro_graphical)\n    print('precision', precision_score(outputs, labels, average='weighted'))\n    print('recall', recall_score(outputs, labels, average='weighted'))\n\n    \n    \n    arr = []\n    for i in range(class_num):\n        arr.append(str(i))\n    print(classification_report(labels, outputs, target_names=arr))\n\n    \nevaluate(model, df_test)\n\nlabel_dict","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yyMASaELyunD","outputId":"d6674630-55b1-4500-a52e-76fd46c4e9d2","execution":{"iopub.status.busy":"2023-01-20T13:05:11.084059Z","iopub.execute_input":"2023-01-20T13:05:11.085205Z","iopub.status.idle":"2023-01-20T13:05:11.287324Z","shell.execute_reply.started":"2023-01-20T13:05:11.085125Z","shell.execute_reply":"2023-01-20T13:05:11.286251Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.23652694610778444\nF1-Score macro:  0.18828670075548443\nF1-Score micro:  0.23652694610778444\nprecision 0.3145331144850527\nrecall 0.23652694610778444\n              precision    recall  f1-score   support\n\n           0       0.14      0.24      0.17        34\n           1       0.27      0.48      0.35        25\n           2       0.20      0.21      0.21        33\n           3       0.10      0.15      0.12        20\n           4       0.00      0.00      0.00         9\n           5       0.00      0.00      0.00        16\n           6       0.00      0.00      0.00        15\n           7       0.57      0.57      0.57        23\n           8       0.31      0.45      0.37        20\n           9       0.35      0.56      0.43        16\n          10       0.20      0.15      0.17        26\n          11       0.00      0.00      0.00         4\n          12       0.07      0.08      0.07        12\n          13       0.00      0.00      0.00        23\n          14       0.32      0.50      0.39        12\n          15       0.42      0.26      0.32        19\n          16       0.20      0.10      0.13        10\n          17       0.17      0.06      0.09        17\n\n    accuracy                           0.24       334\n   macro avg       0.18      0.21      0.19       334\nweighted avg       0.20      0.24      0.21       334\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'monasebat': 0,\n 'siyasi': 1,\n 'tablighat va business': 2,\n 'asheqane': 3,\n 'angizeshi': 4,\n 'sher va adabiyat': 5,\n 'majazi': 6,\n 'elmi': 7,\n 'ejtemayi': 8,\n 'IT': 9,\n 'nasihat va sokhan': 10,\n 'dars va daneshgah': 11,\n 'zibayi': 12,\n 'mazhabi': 13,\n 'varzeshi': 14,\n 'melk o maskan': 15,\n 'tourist va amaken': 16,\n 'pezeshki': 17}"},"metadata":{}}]},{"cell_type":"code","source":"filepath = \"graphical\"\ntorch.save(model.state_dict(), \"graphical\")\n","metadata":{"id":"M-42pZ-32_cr","execution":{"iopub.status.busy":"2023-01-20T13:05:11.288958Z","iopub.execute_input":"2023-01-20T13:05:11.289334Z","iopub.status.idle":"2023-01-20T13:05:11.300099Z","shell.execute_reply.started":"2023-01-20T13:05:11.289297Z","shell.execute_reply":"2023-01-20T13:05:11.298954Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(filepath))\nmodel.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZRiSH9D3cjk","outputId":"20de6cfd-cbcb-4eba-d303-554bf1f4c843","execution":{"iopub.status.busy":"2023-01-20T13:05:11.303078Z","iopub.execute_input":"2023-01-20T13:05:11.303380Z","iopub.status.idle":"2023-01-20T13:05:11.315971Z","shell.execute_reply.started":"2023-01-20T13:05:11.303353Z","shell.execute_reply":"2023-01-20T13:05:11.314952Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"GraphicalClassifier(\n  (fc_back): Linear(in_features=36, out_features=100, bias=True)\n  (fc_textcolor): Linear(in_features=12, out_features=100, bias=True)\n  (fc_font): Linear(in_features=16, out_features=100, bias=True)\n  (fc_hidden_back): Linear(in_features=100, out_features=25, bias=True)\n  (fc_hidden_textcolor): Linear(in_features=100, out_features=20, bias=True)\n  (fc_hiddent_font): Linear(in_features=100, out_features=22, bias=True)\n  (fc_tab): Linear(in_features=67, out_features=18, bias=True)\n  (relu): ReLU()\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Text Classification","metadata":{"id":"UNboco9AzJBa"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import BertTokenizer\nimport torch.nn.functional as Fun\n# check_point= \"bert-base-uncased\"\ncheck_point= \"sentence-transformers/LaBSE\"\n# check_point=\"HooshvareLab/bert-base-parsbert-uncased\"\ntokenizer = BertTokenizer.from_pretrained(check_point)\nlabels = label_dict\n\nclass TextDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n\n        self.labels =[label for label in df['label']]\n        self.texts = [tokenizer(text, \n                               padding='max_length', max_length = 512, truncation=True,\n                                return_tensors=\"pt\") for text in df['content']]\n                                \n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        return self.texts[idx]\n    \n    \n    def __getitem__(self, idx):\n\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        return batch_texts, batch_y\n","metadata":{"id":"l6NhCSCXzDZS","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["12bdcf390b604cc38322fb126d851966","2fd28b315c3b4a408f867e89276bd85e","4689bdf1a12c44b59c7eda40593e854f","93953357e9a54d00b13225e41fc572fa","cbfe6cac2c1347a6be552be0b288769b","eb7c320b7ddc4f6ab2d5e6aa191cb6ce","2031fea5f43243d6aca0f73ab451ea43","44dae95043ee48cc88581a6643da15b2","8698ed7d1de9477c96d2aea11aa6b34c","1f6c0550f09b4a98a1b8b739847e2860","d3af71eb71a547f3803daa258a9f7df5","695bfe67ec5b4a978320d871c5d4e105","4cb746a478694037be454cfbd2764231","6ab43e12b86841ef9f68f68c63ffbfba","86a65e5fcf5f4329af63ff351a3e1d46","e51024dad0e145b1bec6a2eb30083dec","b6843efc3e374708904e03482b4c278e","a53999b2748f42c89cfcc0286be01a59","e8076a8f15ef40bdb14c886fb5f9c804","1b2fe4d892dd48648f51cb1cb4d3500e","811bdba102874647b586a024547ad59a","3a737faee52b406b8fb5b83a7a731672"]},"outputId":"5d8c4c6b-42c9-459e-fda6-8f1e8258cb0b","execution":{"iopub.status.busy":"2023-01-20T13:05:11.317662Z","iopub.execute_input":"2023-01-20T13:05:11.318011Z","iopub.status.idle":"2023-01-20T13:05:23.160476Z","shell.execute_reply.started":"2023-01-20T13:05:11.317977Z","shell.execute_reply":"2023-01-20T13:05:23.159445Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.98M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37241fc700294d1f9ec24837bebebc1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4301b759baf440adbb9d60c58b893c13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef31a0a8e24d426baaa8d4d910483d6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/804 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5d90897bb14e48a7a3e5c3042ea43b"}},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nfrom transformers import BertModel,AutoModelForMaskedLM,AutoModel\n\nclass TextClassifier(nn.Module):\n\n    def __init__(self, dropout=0.5):\n\n        super(TextClassifier, self).__init__()\n        seed = 0\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)\n        self.bert =BertModel.from_pretrained(check_point)\n        self.dropout = nn.Dropout(dropout)\n        self.fc1  = nn.Linear(768, class_num)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.relu = nn.ReLU()\n        \n    def forward(self, input_id, mask):\n        \n        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        fc1 = self.fc1(dropout_output)\n        # final_layer = self.softmax(fc1)\n        \n        return self.relu(fc1)","metadata":{"id":"mvK4JKpN0ENC","execution":{"iopub.status.busy":"2023-01-20T13:05:23.162042Z","iopub.execute_input":"2023-01-20T13:05:23.162659Z","iopub.status.idle":"2023-01-20T13:05:23.172579Z","shell.execute_reply.started":"2023-01-20T13:05:23.162620Z","shell.execute_reply":"2023-01-20T13:05:23.171547Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train, val, test = TextDataset(df_train), TextDataset(df_val), TextDataset(df_test)\ntrain_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size)\nval_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\ntest_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:05:23.174131Z","iopub.execute_input":"2023-01-20T13:05:23.174981Z","iopub.status.idle":"2023-01-20T13:05:26.897489Z","shell.execute_reply.started":"2023-01-20T13:05:23.174941Z","shell.execute_reply":"2023-01-20T13:05:26.896515Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam\nfrom tqdm import tqdm\n\ndef train(model, train_data, val_data, learning_rate, epochs, batch_size):\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr= learning_rate)\n    \n    if use_cuda:\n            model = model.cuda()\n            criterion = criterion.cuda()\n    early_stopper = EarlyStopper(patience=2, min_delta=0.01)\n   \n    for epoch_num in range(epochs):\n\n            total_acc_train = 0\n            total_loss_train = 0\n            \n            for train_input, train_label in tqdm(train_dataloader):\n\n                mask = train_input['attention_mask'].to(device)\n                input_id = train_input['input_ids'].squeeze(1).to(device)\n                train_label = train_label.to(device)\n\n                output = model(input_id, mask)\n                batch_loss = criterion(output, train_label)\n                total_loss_train += batch_loss.item()\n                \n                acc = (output.argmax(dim=1) == train_label).sum().item()\n                total_acc_train += acc\n\n                model.zero_grad()\n                batch_loss.backward()\n                optimizer.step()\n            total_acc_val = 0\n            total_loss_val = 0\n            \n            with torch.no_grad():\n            \n                for val_input, val_label in val_dataloader:\n                   \n                    mask = val_input['attention_mask'].to(device)\n                    input_id = val_input['input_ids'].squeeze(1).to(device)\n\n                    val_label = val_label.to(device)\n                    output = model(input_id, mask)\n                    \n                    batch_loss = criterion(output, val_label)\n                    total_loss_val += batch_loss.item()\n                    \n                    acc = (output.argmax(dim=1) == val_label).sum().item()\n                    total_acc_val += acc\n                    \n            print(\n                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(df_train): .3f} \\\n                 | Train Accuracy: {total_acc_train / len(df_train): .3f} \\\n                 | Val Loss: {total_loss_val / len(df_val): .3f} \\\n                 | Val Accuracy: {total_acc_val / len(df_val): .3f}')\n            \n            if early_stopper.early_stop(total_loss_val / len(val_data)): \n                print(\"Early Stopped.\")\n                break\n\nEPOCHS = 10\nmodel = TextClassifier()\nLR = 5e-5\nbatch_size = 8\n              \ntrain(model, df_train, df_val, LR, EPOCHS, batch_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2u69DGgB0mmz","outputId":"55f14926-4ced-4224-c48d-e7497030a26a","execution":{"iopub.status.busy":"2023-01-20T13:05:26.899132Z","iopub.execute_input":"2023-01-20T13:05:26.899513Z","iopub.status.idle":"2023-01-20T13:22:14.290311Z","shell.execute_reply.started":"2023-01-20T13:05:26.899460Z","shell.execute_reply":"2023-01-20T13:22:14.289146Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.75G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20569d55602e4431a8c286cd911b2750"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 334/334 [02:40<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  0.180                  | Train Accuracy:  0.610                  | Val Loss:  0.102                  | Val Accuracy:  0.787\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [02:40<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Train Loss:  0.066                  | Train Accuracy:  0.855                  | Val Loss:  0.087                  | Val Accuracy:  0.811\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [02:40<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Train Loss:  0.036                  | Train Accuracy:  0.925                  | Val Loss:  0.106                  | Val Accuracy:  0.781\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [02:40<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Train Loss:  0.020                  | Train Accuracy:  0.963                  | Val Loss:  0.095                  | Val Accuracy:  0.820\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [02:40<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 5 | Train Loss:  0.013                  | Train Accuracy:  0.977                  | Val Loss:  0.124                  | Val Accuracy:  0.775\nEarly Stopped.\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model):\n    \n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    total_acc_test = 0\n    outputs = []\n    labels = []\n    with torch.no_grad():\n         \n        for test_input, test_label in test_dataloader:\n        \n            test_label = test_label.to(device)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n\n            output =  model(input_id, mask)\n\n            acc = (output.argmax(dim=1) == test_label).sum().item()\n            total_acc_test += acc\n            for i in output.argmax(dim=1).tolist():\n                outputs.append(i)\n            for i in test_label.cpu():\n                labels.append(i)\n                \n    global f1_micro_textual \n    global f1_macro_textual \n    global acc_textual \n    acc_textual = total_acc_test / len(df_test)\n    f1_macro_textual = f1_score(outputs, labels, average='macro')\n    f1_micro_textual = f1_score(outputs, labels, average='micro')\n    print(f'Test Accuracy: {acc_textual}')\n    print('F1-Score macro: ',f1_macro_textual )\n    print('F1-Score micro: ',f1_micro_textual )\n    print('precision', precision_score(outputs, labels, average='weighted'))\n    print('recall', recall_score(outputs, labels, average='weighted'))\n    arr = []\n    for i in range(class_num):\n        arr.append(str(i))\n    print(classification_report(labels, outputs, target_names=arr))\n\n    \nevaluate(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fk-ice5eJSu9","outputId":"babdd61f-d419-4a8d-c50d-f16996276dd8","execution":{"iopub.status.busy":"2023-01-20T13:22:14.332594Z","iopub.execute_input":"2023-01-20T13:22:14.333364Z","iopub.status.idle":"2023-01-20T13:22:20.137736Z","shell.execute_reply.started":"2023-01-20T13:22:14.333329Z","shell.execute_reply":"2023-01-20T13:22:20.136712Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7125748502994012\nF1-Score macro:  0.7300719597574302\nF1-Score micro:  0.7125748502994012\nprecision 0.7410118015900008\nrecall 0.7125748502994012\n              precision    recall  f1-score   support\n\n           0       0.86      0.94      0.90        34\n           1       0.84      0.84      0.84        25\n           2       0.92      0.73      0.81        33\n           3       0.80      0.60      0.69        20\n           4       0.44      0.44      0.44         9\n           5       0.77      0.62      0.69        16\n           6       0.65      0.87      0.74        15\n           7       0.92      0.48      0.63        23\n           8       0.25      0.75      0.37        20\n           9       0.87      0.81      0.84        16\n          10       0.55      0.62      0.58        26\n          11       1.00      0.75      0.86         4\n          12       0.92      0.92      0.92        12\n          13       1.00      0.43      0.61        23\n          14       0.92      0.92      0.92        12\n          15       1.00      0.74      0.85        19\n          16       0.67      0.60      0.63        10\n          17       1.00      0.71      0.83        17\n\n    accuracy                           0.71       334\n   macro avg       0.80      0.71      0.73       334\nweighted avg       0.80      0.71      0.73       334\n\n","output_type":"stream"}]},{"cell_type":"code","source":"filepath =\"text\"\ntorch.save(model.state_dict(), filepath)","metadata":{"id":"CSI-K4zu6AhE","execution":{"iopub.status.busy":"2023-01-20T13:22:20.139325Z","iopub.execute_input":"2023-01-20T13:22:20.139941Z","iopub.status.idle":"2023-01-20T13:22:26.549593Z","shell.execute_reply.started":"2023-01-20T13:22:20.139902Z","shell.execute_reply":"2023-01-20T13:22:26.548556Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(filepath))\n# model","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2rfi_9U6K6N","outputId":"e773ff8f-ac5f-419d-e997-1d6931701b8e","execution":{"iopub.status.busy":"2023-01-20T13:22:26.551357Z","iopub.execute_input":"2023-01-20T13:22:26.551755Z","iopub.status.idle":"2023-01-20T13:22:28.047891Z","shell.execute_reply.started":"2023-01-20T13:22:26.551718Z","shell.execute_reply":"2023-01-20T13:22:28.046559Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Ensemble","metadata":{"id":"0jmzwsgs6aMF"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import BertTokenizer\nimport torch.nn.functional as Fun\ntokenizer = BertTokenizer.from_pretrained(check_point)\nlabels = label_dict\n\nclass EnsembleDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n\n\n        self.labels =[label for label in df['label']]\n        self.texts = [tokenizer(text, \n                               padding='max_length', max_length = 300, truncation=True,\n                                return_tensors=\"pt\") for text in df['content']]\n        self.back = [g for g in df['background']]\n        self.textcolor = [g for g in df['textcolor']]\n        self.font = [g for g in df['font']]\n        \n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        return self.texts[idx]\n    \n    def get_batch_back(self, idx):\n        return self.back[idx]\n \n    def get_batch_textcolor(self, idx):\n        return self.textcolor[idx]\n\n    def get_batch_font(self, idx):\n        return self.font[idx]\n    \n    def __getitem__(self, idx):\n\n        batch_texts = self.get_batch_texts(idx)\n        batch_back  = self.get_batch_back(idx)\n        batch_textcolor  = self.get_batch_textcolor(idx)\n        batch_font  = self.get_batch_font(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        max_value_back = np.max(np.max(df['background'].unique()))\n        values_tensor = torch.tensor(batch_back)\n        output_back = Fun.one_hot(values_tensor, num_classes = max_value_back+1)\n        \n        max_value_textcolor = np.max(np.max(df['textcolor'].unique()))\n        values_tensor = torch.tensor(batch_textcolor)\n        output_textcolor = Fun.one_hot(values_tensor, num_classes = max_value_textcolor+1)\n        \n        max_value_font = np.max(np.max(df['font'].unique()))\n        values_tensor = torch.tensor(batch_font)\n        output_font = Fun.one_hot(values_tensor, num_classes = max_value_font+1)\n        \n        return batch_texts, output_back, output_textcolor, output_font, batch_y\n","metadata":{"id":"XmBrGkh7DvnY","execution":{"iopub.status.busy":"2023-01-20T13:22:28.054574Z","iopub.execute_input":"2023-01-20T13:22:28.058262Z","iopub.status.idle":"2023-01-20T13:22:35.000933Z","shell.execute_reply.started":"2023-01-20T13:22:28.058196Z","shell.execute_reply":"2023-01-20T13:22:34.999940Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class MyEnsemble(nn.Module):\n    def __init__(self, modelA, modelB):\n        \n        super(MyEnsemble, self).__init__()\n        seed = 0\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)\n            \n        self.modelA = modelA\n        self.modelB = modelB\n        self.relu = nn.ReLU()\n        self.linear1 = nn.Linear(class_num*2, class_num)\n        self.linear2 = nn.Linear(class_num,   class_num)\n\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self,input_id, mask, back, textcolor, font):\n        x1 = self.modelA(back, textcolor, font)\n        x2 = self.modelB(input_id, mask)\n        x = torch.cat((x1, x2), dim=1)\n        x = self.linear1(x)\n#         x = self.relu(x)\n        # x = self.linear2(x)\n        x = self.softmax(x)\n\n        return x","metadata":{"id":"7tnQe6MF6d2-","execution":{"iopub.status.busy":"2023-01-20T13:22:35.002153Z","iopub.execute_input":"2023-01-20T13:22:35.002835Z","iopub.status.idle":"2023-01-20T13:22:35.010524Z","shell.execute_reply.started":"2023-01-20T13:22:35.002799Z","shell.execute_reply":"2023-01-20T13:22:35.009365Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"modelA = GraphicalClassifier()\nmodelB = TextClassifier()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSIDesdC6mB9","outputId":"bfe4ad3a-ef65-4cd4-c100-c0486cb10d54","execution":{"iopub.status.busy":"2023-01-20T13:22:35.011938Z","iopub.execute_input":"2023-01-20T13:22:35.012677Z","iopub.status.idle":"2023-01-20T13:22:43.978950Z","shell.execute_reply.started":"2023-01-20T13:22:35.012641Z","shell.execute_reply":"2023-01-20T13:22:43.977974Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"modelA.load_state_dict(torch.load(\"graphical\"))\n# modelB.load_state_dict(torch.load(\"text\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vc3AT0GU6uiV","outputId":"e70bb20b-4607-42a1-fd87-3ccabd1e4119","execution":{"iopub.status.busy":"2023-01-20T13:22:43.980469Z","iopub.execute_input":"2023-01-20T13:22:43.981096Z","iopub.status.idle":"2023-01-20T13:22:43.995155Z","shell.execute_reply.started":"2023-01-20T13:22:43.981058Z","shell.execute_reply":"2023-01-20T13:22:43.994318Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.optim import Adam\nfrom tqdm import tqdm\n        \nmodel = MyEnsemble(modelA, modelB)\n\ntrain_ensemble, val_ensemble = EnsembleDataset(df_train), EnsembleDataset(df_val)\ntrain_dataloader_ensemble = torch.utils.data.DataLoader(train_ensemble, batch_size=batch_size, shuffle=True)\nval_dataloader_ensemble = torch.utils.data.DataLoader(val_ensemble, batch_size=batch_size)\n\nuse_cuda = torch.cuda.is_available()\n\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nEpochs = 10\nlearning_rate = 5e-5\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr= learning_rate)\n  \nif use_cuda:\n    \n    model = model.cuda()\n\nearly_stopper = EarlyStopper(patience=2, min_delta=0.01)\n\nfor epoch_num in range(Epochs):\n\n    total_acc_train = 0\n    total_loss_train = 0\n        \n    for train_input, input_back, input_textcolor, input_font, train_label in tqdm(train_dataloader_ensemble):\n        mask = train_input['attention_mask'].to(device)\n        input_id = train_input['input_ids'].squeeze(1).to(device)\n        back = input_back.to(device)\n        textcolor = input_textcolor.to(device)\n        font = input_font.to(device)\n        train_label = train_label.to(device)\n\n        output = model(input_id, mask, back, textcolor, font)\n        batch_loss = criterion(output, train_label)\n        total_loss_train += batch_loss.item()\n\n        acc = (output.argmax(dim=1) == train_label).sum().item()\n        total_acc_train += acc\n\n        model.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n\n\n    total_acc_val = 0\n    total_loss_val = 0\n    with torch.no_grad():      \n        for val_input, val_back, val_textcolor, val_font, val_label in val_dataloader_ensemble:\n            mask = val_input['attention_mask'].to(device)\n            input_id = val_input['input_ids'].squeeze(1).to(device)\n\n            back = val_back.to(device)\n            textcolor = val_textcolor.to(device)\n            font = val_font.to(device)\n            output = model(input_id, mask,back, textcolor, font)\n            val_label = val_label.to(device)\n            batch_loss = criterion(output, val_label)\n            total_loss_val += batch_loss.item()\n\n            acc = (output.argmax(dim=1) == val_label).sum().item()\n            total_acc_val += acc\n\n    print(\n    f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(df_train): .3f} \\\n    | Train Accuracy: {total_acc_train / len(df_train): .3f}\\\n    | Val Loss: {total_loss_val / len(df_val): .3f} \\\n    | Val Accuracy: {total_acc_val / len(df_val): .3f}')  \n\n    if early_stopper.early_stop(total_loss_val / len(df_val)): \n        print(\"Early Stopped.\")\n        break\n      \n    # print(f'Ensemble Accuracy: {total_acc_train / len(df_train): .3f}')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_g7tflkyRLjq","outputId":"828074f7-5fad-44fc-9e35-7ec6dc9d4d8f","execution":{"iopub.status.busy":"2023-01-20T13:22:43.997920Z","iopub.execute_input":"2023-01-20T13:22:43.998177Z","iopub.status.idle":"2023-01-20T13:42:17.725594Z","shell.execute_reply.started":"2023-01-20T13:22:43.998151Z","shell.execute_reply":"2023-01-20T13:42:17.724575Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"100%|██████████| 334/334 [01:53<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  0.249     | Train Accuracy:  0.453    | Val Loss:  0.185     | Val Accuracy:  0.658\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:52<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Train Loss:  0.126     | Train Accuracy:  0.784    | Val Loss:  0.123     | Val Accuracy:  0.781\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:53<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Train Loss:  0.080     | Train Accuracy:  0.866    | Val Loss:  0.126     | Val Accuracy:  0.778\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:52<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Train Loss:  0.051     | Train Accuracy:  0.926    | Val Loss:  0.119     | Val Accuracy:  0.808\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:52<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 5 | Train Loss:  0.036     | Train Accuracy:  0.949    | Val Loss:  0.119     | Val Accuracy:  0.805\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:52<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 6 | Train Loss:  0.023     | Train Accuracy:  0.966    | Val Loss:  0.121     | Val Accuracy:  0.799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:53<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 7 | Train Loss:  0.018     | Train Accuracy:  0.972    | Val Loss:  0.127     | Val Accuracy:  0.811\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:53<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 8 | Train Loss:  0.013     | Train Accuracy:  0.983    | Val Loss:  0.128     | Val Accuracy:  0.814\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:53<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 9 | Train Loss:  0.019     | Train Accuracy:  0.971    | Val Loss:  0.167     | Val Accuracy:  0.769\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 334/334 [01:53<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 10 | Train Loss:  0.026     | Train Accuracy:  0.955    | Val Loss:  0.135     | Val Accuracy:  0.784\nEarly Stopped.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score,classification_report\n\ndef evaluate(model, test_data):\n    \n    test = EnsembleDataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=8)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    outputs = []\n    labels = []\n    total_acc_test = 0\n    with torch.no_grad():\n         \n        for test_input, test_back, test_textcolor, test_font, test_label in test_dataloader:\n        \n            test_label = test_label.to(device)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n            back = test_back.to(device)\n            textcolor = test_textcolor.to(device)\n            font = test_font.to(device)\n\n            output =  model(input_id, mask, back, textcolor, font)\n\n            acc = (output.argmax(dim=1) == test_label).sum().item()\n            total_acc_test += acc\n            \n            for i in output.argmax(dim=1).tolist():\n                outputs.append(i)\n            for i in test_label.cpu():\n                labels.append(i)\n                \n    global f1_micro_ensemble \n    global f1_macro_ensemble \n    global acc_ensemble \n    \n    acc_ensemble = total_acc_test / len(test_data)\n    f1_macro_ensemble = f1_score(outputs, labels, average='macro')\n    f1_micro_ensemble = f1_score(outputs, labels, average='micro')\n    \n    \n    print(f'Test Accuracy: {acc_ensemble}')\n    print('F1-Score macro: ',f1_macro_ensemble )\n    print('F1-Score micro: ',f1_micro_ensemble )\n    print('precision', precision_score(outputs, labels, average='weighted'))\n    print('recall', recall_score(outputs, labels, average='weighted'))\n    arr = []\n    for i in range(class_num):\n        arr.append(str(i))\n    print(classification_report(labels, outputs, target_names=arr))\n\n    \nevaluate(model, df_test)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lv_W5rrl68nO","outputId":"6d1d0ba5-6e02-4f47-8dcd-9ffe4d397add","execution":{"iopub.status.busy":"2023-01-20T13:42:17.746105Z","iopub.execute_input":"2023-01-20T13:42:17.746696Z","iopub.status.idle":"2023-01-20T13:42:22.116742Z","shell.execute_reply.started":"2023-01-20T13:42:17.746658Z","shell.execute_reply":"2023-01-20T13:42:22.115418Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.8173652694610778\nF1-Score macro:  0.8192866398151494\nF1-Score micro:  0.8173652694610778\nprecision 0.8340494584740612\nrecall 0.8173652694610778\n              precision    recall  f1-score   support\n\n           0       0.83      1.00      0.91        34\n           1       0.84      0.84      0.84        25\n           2       0.83      0.88      0.85        33\n           3       0.76      0.80      0.78        20\n           4       0.54      0.78      0.64         9\n           5       0.67      0.62      0.65        16\n           6       0.71      0.80      0.75        15\n           7       0.65      0.87      0.74        23\n           8       0.87      0.65      0.74        20\n           9       0.88      0.88      0.88        16\n          10       0.89      0.62      0.73        26\n          11       0.80      1.00      0.89         4\n          12       1.00      0.92      0.96        12\n          13       0.89      0.74      0.81        23\n          14       0.92      1.00      0.96        12\n          15       1.00      0.79      0.88        19\n          16       0.91      1.00      0.95        10\n          17       0.92      0.71      0.80        17\n\n    accuracy                           0.82       334\n   macro avg       0.83      0.83      0.82       334\nweighted avg       0.83      0.82      0.82       334\n\n","output_type":"stream"}]},{"cell_type":"code","source":"label_dict","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:42:22.118461Z","iopub.execute_input":"2023-01-20T13:42:22.118861Z","iopub.status.idle":"2023-01-20T13:42:22.126415Z","shell.execute_reply.started":"2023-01-20T13:42:22.118830Z","shell.execute_reply":"2023-01-20T13:42:22.125209Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'monasebat': 0,\n 'siyasi': 1,\n 'tablighat va business': 2,\n 'asheqane': 3,\n 'angizeshi': 4,\n 'sher va adabiyat': 5,\n 'majazi': 6,\n 'elmi': 7,\n 'ejtemayi': 8,\n 'IT': 9,\n 'nasihat va sokhan': 10,\n 'dars va daneshgah': 11,\n 'zibayi': 12,\n 'mazhabi': 13,\n 'varzeshi': 14,\n 'melk o maskan': 15,\n 'tourist va amaken': 16,\n 'pezeshki': 17}"},"metadata":{}}]},{"cell_type":"code","source":"print(\"On \", len(df['label'].value_counts()), \" Labels\")\ncolumns = ['Method', 'Accuracy', 'F1-Macro', 'F1-Moicro']\nresults = pd.DataFrame(columns =columns)\nresults.style.set_caption(\"Hello World\")\ngraphical_result = {'Method': 'Graphical', 'Accuracy': round(acc_graphical,3), 'F1-Macro': round(f1_macro_graphical,3), 'F1-Moicro':round(f1_micro_graphical,3)}\nresults = results.append(graphical_result, ignore_index = True)\ntextual_result = {'Method': 'Textual', 'Accuracy': round(acc_textual,3), 'F1-Macro': round(f1_macro_textual,3), 'F1-Moicro':round(f1_micro_textual,3)}\nresults = results.append(textual_result, ignore_index = True)\nensemble_result = {'Method': 'Ensemble', 'Accuracy': round(acc_ensemble,3), 'F1-Macro': round(f1_macro_ensemble,3), 'F1-Moicro':round(f1_micro_ensemble,3)}\nresults = results.append(ensemble_result, ignore_index = True)\nresults\n","metadata":{"execution":{"iopub.status.busy":"2023-01-20T13:42:22.128222Z","iopub.execute_input":"2023-01-20T13:42:22.129289Z","iopub.status.idle":"2023-01-20T13:42:22.206347Z","shell.execute_reply.started":"2023-01-20T13:42:22.129247Z","shell.execute_reply":"2023-01-20T13:42:22.205336Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"On  18  Labels\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"      Method  Accuracy  F1-Macro  F1-Moicro\n0  Graphical     0.237     0.188      0.237\n1    Textual     0.713     0.730      0.713\n2   Ensemble     0.817     0.819      0.817","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Accuracy</th>\n      <th>F1-Macro</th>\n      <th>F1-Moicro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Graphical</td>\n      <td>0.237</td>\n      <td>0.188</td>\n      <td>0.237</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Textual</td>\n      <td>0.713</td>\n      <td>0.730</td>\n      <td>0.713</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ensemble</td>\n      <td>0.817</td>\n      <td>0.819</td>\n      <td>0.817</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}